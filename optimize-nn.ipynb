{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from truss_casadi import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "joints = [\n",
    "    Joint(JointType.PIN),  # 0\n",
    "    Joint(JointType.GUSSET), # 1\n",
    "    Joint(JointType.GUSSET), # 2\n",
    "    Joint(JointType.GUSSET), # 3\n",
    "    Joint(JointType.ROLLER), # 4 \n",
    "    Joint(JointType.GUSSET), # 5\n",
    "    Joint(JointType.GUSSET), # 6\n",
    "    Joint(JointType.GUSSET), # 7\n",
    "    Joint(JointType.GUSSET), # 8\n",
    "    Joint(JointType.GUSSET)] # 9\n",
    "\n",
    "\n",
    "links = [Link(0, 1), Link(1,2), Link(2,3), Link(3,4), Link(0,5), Link(1,5), Link(1,6), Link(2,6), Link(2,7), Link(2,8), Link(3,8), Link(3,9), Link(4,9), Link(5,6), Link(6,7), Link(7,8), Link(8,9)]\n",
    "\n",
    "FORCE_PER_M = 2.5\n",
    "bridge_joints = [0, 1, 2, 3, 4]\n",
    "train_force = Force(fx=0, fy=FORCE_PER_M, joints=bridge_joints)\n",
    "\n",
    "forces = [train_force]\n",
    "\n",
    "truss = Truss(joints, links, forces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "half_len_unknowns = len(joints)\n",
    "\n",
    "inputs = [-1]*half_len_unknowns*2\n",
    "inputs[bridge_joints[0]] = 0\n",
    "inputs[bridge_joints[-1]] = 14\n",
    "for i in bridge_joints:\n",
    "    inputs[i + half_len_unknowns] = 0\n",
    "\n",
    "cost_ = Function('cost_', [truss.xs], [truss.cost])\n",
    "\n",
    "def constraints():\n",
    "    inequalities = []\n",
    "    inequality_funs = []\n",
    "    inequality_gradients = []\n",
    "    for link in truss.links:\n",
    "        leng_fun = Function('leng_fun', [truss.xs], [link.length])\n",
    "        force_fun = Function('force_fun', [truss.xs], [link.force])   \n",
    "        # Constraint: length of each link cannot be less than 1\n",
    "        # inequalities.append(-leng_fun(truss.xs)+1)\n",
    "        inequalities.append(-link.length + 1)\n",
    "        inequality_funs.append(Function('length_greater_than_one', [truss.xs], [-link.length + 1]))\n",
    "        inequality_gradients.append(Function('del_length_greater_than_one', [truss.xs], [casadi.gradient(-link.length + 1, truss.xs)]))\n",
    "        # Constraint: force of each link must be within -27 and 18\n",
    "        inequalities.append(link.force - 6*3)\n",
    "        inequality_funs.append(Function('force_less_than_18', [truss.xs], [link.force - 6*3]))\n",
    "        # inequalities.append(force_fun(truss.xs) - 6*3)\n",
    "        inequalities.append(-link.force - 9*3)\n",
    "        inequality_funs.append(Function('force_greater_than_27', [truss.xs], [-link.force - 9*3]))\n",
    "        # inequalities.append(-force_fun(truss.xs) - 9*3)\n",
    "\n",
    "\n",
    "    for i in range(len(bridge_joints)-1):\n",
    "        i0 = bridge_joints[i]\n",
    "        i1 = bridge_joints[i+1]\n",
    "\n",
    "        # Constraint: Each bridge joint must not be more than 3.5m apart\n",
    "        # inequalities.append(truss.xs[i1] - truss.xs[i0] - 3.5)\n",
    "        inequalities.append(truss.xs[i1] - truss.xs[i0] - 3.5)\n",
    "        inequality_funs.append(Function('bridge_spacing', [truss.xs], [truss.xs[i1] - truss.xs[i0] - 3.5]))\n",
    "\n",
    "        # Constraint: Bridge joints must be in order of ascending X value\n",
    "        # inequalities.append(truss.xs[i0] - truss.xs[i1])\n",
    "        inequalities.append(truss.xs[i0] - truss.xs[i1])\n",
    "        inequality_funs.append(Function('bridge_ascending', [truss.xs], [truss.xs[i0] - truss.xs[i1]]))\n",
    "\n",
    "    return inequalities, inequality_funs\n",
    "\n",
    "inequalities, inequality_funs = constraints()\n",
    "del_ineq_fn = Function('del_ineq_fn', [truss.xs], [casadi.gradient(casadi.norm_2(casadi.fmax(casadi.horzcat(*inequalities), 0)), truss.xs)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def populate_unknowns(x):\n",
    "#     if(len(x.size()) == 2):\n",
    "#         final = []\n",
    "#         for j in range(x.size()[0]):\n",
    "#             x_iter = iter(x[j])\n",
    "#             xs = inputs.copy()\n",
    "#             for i in range(len(inputs)):\n",
    "#                 xs[i] = inputs[i] if inputs[i] != -1 else next(x_iter)\n",
    "#             final.append(xs)\n",
    "#         return torch.tensor(final, requires_grad=True).to(DEVICE)\n",
    "#     else:\n",
    "#         x_iter = iter(x)\n",
    "#         xs = inputs.copy()\n",
    "#         for i in range(len(inputs)):\n",
    "#             xs[i] = inputs[i] if inputs[i] != -1 else next(x_iter)\n",
    "#         return torch.tensor(xs, requires_grad=True).to(DEVICE)\n",
    "\n",
    "# def extract_unknowns(x):\n",
    "#     if(len(x.size()) == 2):\n",
    "#         all_xs = []\n",
    "#         for j in range(len(x)):\n",
    "#             xs = []\n",
    "#             for i in range(len(inputs)):\n",
    "#                 if inputs[i] == -1:\n",
    "#                     print(x[j])\n",
    "#                     n = float(x[j][i])\n",
    "#                     if math.isnan(n):\n",
    "#                         n = 0.0\n",
    "#                     xs.append(n)   \n",
    "#             all_xs.append(xs)\n",
    "#         return torch.tensor(all_xs, requires_grad=True).to(DEVICE) \n",
    "#     else:\n",
    "#         xs = []\n",
    "#         for i in range(len(inputs)):\n",
    "#             if inputs[i] == -1:\n",
    "#                 n = float(x[i])\n",
    "#                 if math.isnan(n):\n",
    "#                     n = 0.0\n",
    "#                 xs.append(n)\n",
    "#         return torch.tensor(xs, requires_grad=True).to(DEVICE)\n",
    "    \n",
    "\n",
    "# def cost_fn(y):\n",
    "#     return float(cost_(populate_unknowns(y).cpu().detach().numpy().flatten()))\n",
    "\n",
    "# # inequality function g_x(y) <= 0\n",
    "# def g_x(y):\n",
    "#     x = populate_unknowns(y)\n",
    "#     G = []\n",
    "#     for eqn in inequality_funs:\n",
    "#         # print(eqn, \"=\", eqn(x))\n",
    "#         G.append([float(eqn(x.cpu().detach().numpy().flatten()))])\n",
    "#     return torch.tensor(G, requires_grad=True).to(DEVICE)\n",
    "\n",
    "# del_ineq_fn = Function('del_ineq_fn', [truss.xs], [casadi.gradient(casadi.norm_2(casadi.fmax(casadi.vertcat(*inequalities), 0)), truss.xs)])\n",
    "# def del_ineq(y):\n",
    "#     if(len(y.size()) == 2):\n",
    "#         xs = []\n",
    "#         for i in range(len(y)):\n",
    "#             xs.append(extract_unknowns(torch.tensor(np.array(del_ineq_fn(populate_unknowns(y[i]).cpu().detach().numpy().flatten())).flatten(),requires_grad=True).to(DEVICE)).cpu().detach().numpy().flatten())\n",
    "#         return torch.tensor(xs, requires_grad=True).to(DEVICE)\n",
    "#     else:\n",
    "#         return extract_unknowns(torch.tensor(np.array(del_ineq_fn(populate_unknowns(y).cpu().detach().numpy().flatten())).flatten(), requires_grad=True).to(DEVICE))\n",
    "\n",
    "\n",
    "# ground_truth = torch.tensor([3.5, 7, 10.5, -6.6+7, -4.1+7, 0, 4.9+7, 6.4+7, -1.9, -4, -4.9, -4, -1.9]).to(DEVICE)\n",
    "\n",
    "# print(populate_unknowns(ground_truth))\n",
    "\n",
    "# n_unknowns = half_len_unknowns*2-len(bridge_joints)-2\n",
    "\n",
    "# # print(del_g_x(ground_truth))\n",
    "# # print(torch.linalg.vector_norm(torch.clamp(del_g_x(ground_truth), min=0), dim=1))\n",
    "\n",
    "# print(g_x(ground_truth))\n",
    "# print(del_ineq(ground_truth))\n",
    "# # cost_fn(ground_truth)\n",
    "# # g_x(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ground_truth_with_knowns \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m0\u001b[39;49m, \u001b[39m3.5\u001b[39;49m, \u001b[39m7\u001b[39;49m, \u001b[39m10.5\u001b[39;49m, \u001b[39m14\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m6.6\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m7\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m4.1\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m7\u001b[39;49m, \u001b[39m7\u001b[39;49m, \u001b[39m4.9\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m7\u001b[39;49m, \u001b[39m6.4\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m7\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1.9\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m4\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m4.9\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m4\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1.9\u001b[39;49m]])\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[1;32m      2\u001b[0m ground_truth \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m3.5\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m10.5\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m6.6\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4.1\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m4.9\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m6.4\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.9\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4.9\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.9\u001b[39m]])\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      3\u001b[0m known_indices \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m17\u001b[39m, \u001b[39m18\u001b[39m, \u001b[39m19\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ground_truth_with_knowns = torch.tensor([[0, 3.5, 7, 10.5, 14, -6.6+7, -4.1+7, 7, 4.9+7, 6.4+7, 0, 0, 0, 0, 0, -1.9, -4, -4.9, -4, -1.9]]).to(DEVICE)\n",
    "ground_truth = torch.tensor([[3.5, 7, 10.5, -6.6+7, -4.1+7, 7, 4.9+7, 6.4+7, -1.9, -4, -4.9, -4, -1.9]]).to(DEVICE)\n",
    "known_indices = [1, 2, 3, 5, 6, 7, 8, 9, 15, 16, 17, 18, 19]\n",
    "replace_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "n_unknowns = 13\n",
    "\n",
    "def remove_unknowns(X):\n",
    "    return X[:, known_indices]\n",
    "\n",
    "def add_knowns(X):\n",
    "    Y = ground_truth_with_knowns.repeat(torch.Size([X.size(dim=0), 1]))\n",
    "    Y[:, known_indices] = X[:, replace_indices]\n",
    "    return Y\n",
    "\n",
    "def cost(Y):\n",
    "    Y_hat = add_knowns(Y).cpu().detach().numpy()\n",
    "    C = []\n",
    "    for x in Y_hat:\n",
    "        C.append(float(cost_(x)))\n",
    "    return torch.tensor(C, requires_grad=True).to(DEVICE)\n",
    "\n",
    "def g_x(Y):\n",
    "    Y_hat = add_knowns(Y).cpu().detach().numpy()\n",
    "    Gs = []\n",
    "    for x in Y_hat:\n",
    "        G = []\n",
    "        for eqn in inequality_funs:\n",
    "            # print(eqn, \"=\", eqn(x))\n",
    "            G.append(float(eqn(x)))\n",
    "        Gs.append(G)\n",
    "    return torch.tensor(Gs, requires_grad=True).nan_to_num(0).to(DEVICE)\n",
    "\n",
    "def ineq_grad(Y):\n",
    "    Y_hat = add_knowns(Y).cpu().detach().numpy()\n",
    "    Gs = []\n",
    "    for x in Y_hat:\n",
    "        Gs.append(np.array(del_ineq_fn(x)).flatten())\n",
    "    return torch.tensor(Gs, requires_grad=True).nan_to_num(0).to(DEVICE)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1353.4351], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([[ -2.5000, -20.7632, -24.2368,  -2.5000, -28.8281, -16.1719,  -2.5000,\n",
      "         -27.9531, -17.0469,  -2.5000, -22.1447, -22.8553,  -0.9416,  -4.5873,\n",
      "         -40.4127,  -2.6359, -26.7217, -18.2783,  -3.0447, -22.2393, -22.7607,\n",
      "          -4.7280, -20.3357, -24.6643,  -3.9000, -23.0398, -21.9602,  -5.3253,\n",
      "         -21.2877, -23.7123,  -3.2379, -24.7973, -20.2027,  -2.4670, -22.2595,\n",
      "         -22.7405,  -0.9925,  -4.2361, -40.7639,  -2.2650,  -4.6799, -40.3201,\n",
      "          -3.1976,  -5.2024, -39.7976,  -3.9820,  -5.2909, -39.7091,  -1.5807,\n",
      "          -4.7393, -40.2607,   0.0000,  -3.5000,   0.0000,  -3.5000,   0.0000,\n",
      "          -3.5000,   0.0000,  -3.5000]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(cost(ground_truth))\n",
    "print(g_x(ground_truth))\n",
    "print(ineq_grad(ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04979815  0.63972217  0.13694563]\n",
      " [ 0.63419678  1.08472149  1.44420107]\n",
      " [ 0.39851485 -0.23787081  0.06135996]\n",
      " [ 0.66401494 -1.29885013 -0.2292368 ]\n",
      " [-0.7709291   1.96366343  0.03149286]]\n"
     ]
    }
   ],
   "source": [
    "G = np.random.normal(loc=0, scale=1., size=(5, 3))\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_dim), \n",
    "            nn.BatchNorm1d(hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim), \n",
    "            nn.BatchNorm1d(hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        ]\n",
    "        \n",
    "        for layer in layers:\n",
    "            if type(layer) == nn.Linear:\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "n_train = 10000\n",
    "n_test = 100\n",
    "train_batch_size = 1000\n",
    "train_X = torch.Tensor(np.random.uniform(-1, 1, size=(n_train, n_unknowns))).to(DEVICE)\n",
    "test_X = torch.Tensor(np.random.uniform(-1, 1, size=(n_test, n_unknowns))).to(DEVICE)\n",
    "\n",
    "train_dataset = TensorDataset(train_X)\n",
    "test_dataset = TensorDataset(test_X)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.0597e-01, -1.4765e+01, -3.0235e+01,  ..., -1.0425e+00,\n",
      "          9.9937e+00, -1.3494e+01],\n",
      "        [ 7.5994e-01,  1.0953e+01, -5.5953e+01,  ..., -6.7351e-01,\n",
      "          1.0109e+01, -1.3609e+01],\n",
      "        [ 8.0489e-02,  2.1376e+01, -6.6377e+01,  ...,  1.5835e-01,\n",
      "          1.1236e+01, -1.4736e+01],\n",
      "        ...,\n",
      "        [ 7.0389e-01,  1.9305e+02, -2.3805e+02,  ...,  3.8483e-02,\n",
      "          1.0126e+01, -1.3626e+01],\n",
      "        [ 6.5772e-01,  1.6313e+01, -6.1313e+01,  ...,  7.8095e-02,\n",
      "          1.0257e+01, -1.3757e+01],\n",
      "        [ 4.6090e-01, -3.5295e+01, -9.7045e+00,  ...,  5.6120e-01,\n",
      "          1.0715e+01, -1.4215e+01]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[ 6.2648e-01,  6.2811e+01, -1.0781e+02,  ..., -5.3202e-01,\n",
      "          9.5018e+00, -1.3002e+01],\n",
      "        [ 6.4881e-01,  1.6779e+02, -2.1279e+02,  ..., -7.0115e-01,\n",
      "          1.0473e+01, -1.3973e+01],\n",
      "        [ 6.0071e-01,  1.0062e+00, -4.6006e+01,  ..., -1.0517e-01,\n",
      "          1.1283e+01, -1.4783e+01],\n",
      "        ...,\n",
      "        [ 9.5734e-01, -3.3084e+01, -1.1916e+01,  ..., -1.3338e+00,\n",
      "          9.6501e+00, -1.3150e+01],\n",
      "        [ 1.9848e-01, -4.4022e+01, -9.7774e-01,  ..., -6.5140e-02,\n",
      "          1.0792e+01, -1.4292e+01],\n",
      "        [ 7.3397e-01,  1.2922e+00, -4.6292e+01,  ..., -1.0128e+00,\n",
      "          9.8392e+00, -1.3339e+01]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[ 3.9610e-01, -5.7963e+01,  1.2963e+01,  ...,  4.0540e-02,\n",
      "          1.0057e+01, -1.3557e+01],\n",
      "        [ 9.3078e-01, -9.7490e+00, -3.5251e+01,  ..., -1.6664e+00,\n",
      "          9.5905e+00, -1.3090e+01],\n",
      "        [ 5.7093e-01, -3.2445e+01, -1.2555e+01,  ...,  3.8388e-01,\n",
      "          1.1311e+01, -1.4811e+01],\n",
      "        ...,\n",
      "        [ 8.3670e-01,  1.8084e+01, -6.3084e+01,  ...,  1.4256e+00,\n",
      "          1.1318e+01, -1.4818e+01],\n",
      "        [ 7.0982e-01, -1.3073e+01, -3.1927e+01,  ..., -9.3713e-01,\n",
      "          1.0178e+01, -1.3678e+01],\n",
      "        [ 7.0262e-01, -4.7376e+02,  4.2876e+02,  ...,  6.8751e-01,\n",
      "          1.0699e+01, -1.4199e+01]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[  0.7666, -27.7343, -17.2657,  ...,  -0.9592,   9.7904, -13.2904],\n",
      "        [  0.4711, -21.9552, -23.0448,  ...,  -0.7358,  10.6483, -14.1483],\n",
      "        [  0.9498, -15.4491, -29.5509,  ...,  -0.9951,  10.1343, -13.6343],\n",
      "        ...,\n",
      "        [  0.8903, -26.3845, -18.6155,  ...,  -0.2573,  10.1464, -13.6464],\n",
      "        [  0.5772,   1.6829, -46.6829,  ...,   0.0863,  11.2941, -14.7941],\n",
      "        [  0.2583, -53.2092,   8.2092,  ...,  -0.1808,  11.0720, -14.5720]],\n",
      "       device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([[ 4.5512e-01,  1.7784e+01, -6.2784e+01,  ...,  8.3782e-01,\n",
      "          1.0626e+01, -1.4126e+01],\n",
      "        [ 2.0153e-01,  3.2528e+01, -7.7528e+01,  ...,  3.9598e-01,\n",
      "          1.0842e+01, -1.4342e+01],\n",
      "        [ 2.3222e-01,  1.5282e+02, -1.9782e+02,  ..., -4.2228e-02,\n",
      "          1.1040e+01, -1.4540e+01],\n",
      "        ...,\n",
      "        [ 1.9969e-01,  1.7459e+01, -6.2459e+01,  ..., -1.4348e+00,\n",
      "          9.8738e+00, -1.3374e+01],\n",
      "        [ 8.4925e-02, -1.2579e+01, -3.2421e+01,  ...,  3.2183e-01,\n",
      "          1.1475e+01, -1.4975e+01],\n",
      "        [ 5.1483e-01,  4.9894e+02, -5.4394e+02,  ...,  5.2649e-01,\n",
      "          1.0709e+01, -1.4209e+01]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[ 5.7148e-01, -4.4786e+01, -2.1426e-01,  ..., -4.3397e-01,\n",
      "          1.0430e+01, -1.3930e+01],\n",
      "        [ 3.4276e-01, -2.0952e+01, -2.4048e+01,  ..., -1.6496e+00,\n",
      "          9.6377e+00, -1.3138e+01],\n",
      "        [ 1.5210e-01, -3.0245e+01, -1.4755e+01,  ..., -4.8843e-01,\n",
      "          1.0223e+01, -1.3723e+01],\n",
      "        ...,\n",
      "        [ 9.1950e-01,  1.1962e+02, -1.6462e+02,  ...,  5.2975e-01,\n",
      "          1.1104e+01, -1.4604e+01],\n",
      "        [ 6.2760e-01,  1.1875e+01, -5.6875e+01,  ...,  9.8595e-01,\n",
      "          1.1290e+01, -1.4790e+01],\n",
      "        [ 8.2765e-01,  1.1080e+01, -5.6080e+01,  ...,  1.1741e+00,\n",
      "          1.1014e+01, -1.4514e+01]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[ 4.5641e-01, -3.2266e+01, -1.2734e+01,  ...,  6.6948e-01,\n",
      "          1.0404e+01, -1.3904e+01],\n",
      "        [ 7.5996e-01, -3.4054e+01, -1.0946e+01,  ...,  1.6437e+00,\n",
      "          1.1371e+01, -1.4871e+01],\n",
      "        [ 8.3482e-01, -6.4449e+00, -3.8555e+01,  ...,  1.5487e-01,\n",
      "          9.7606e+00, -1.3261e+01],\n",
      "        ...,\n",
      "        [ 8.8208e-01,  1.1952e+02, -1.6452e+02,  ...,  1.4185e+00,\n",
      "          1.1127e+01, -1.4627e+01],\n",
      "        [ 2.8762e-01, -2.6732e+01, -1.8268e+01,  ..., -1.7826e-01,\n",
      "          1.0770e+01, -1.4270e+01],\n",
      "        [ 3.6246e-01,  1.2182e+01, -5.7182e+01,  ...,  1.6503e-01,\n",
      "          1.0540e+01, -1.4040e+01]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[  0.6058, -36.5794,  -8.4206,  ...,   0.6573,  10.7622, -14.2622],\n",
      "        [  0.8022, -23.8259, -21.1741,  ...,   0.7979,  10.9211, -14.4211],\n",
      "        [  0.2062,   2.3354, -47.3354,  ...,  -1.2143,   9.7260, -13.2260],\n",
      "        ...,\n",
      "        [  0.9122, -23.6630, -21.3370,  ...,  -1.3964,   9.8585, -13.3585],\n",
      "        [  0.0611,  10.6866, -55.6866,  ...,  -0.7796,  10.3309, -13.8309],\n",
      "        [  0.6105, -14.8084, -30.1916,  ...,   1.5139,  11.4208, -14.9208]],\n",
      "       device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([[ 5.7158e-01, -3.9127e+01, -5.8731e+00,  ..., -4.3016e-01,\n",
      "          9.6041e+00, -1.3104e+01],\n",
      "        [ 5.0447e-01, -4.3000e+00, -4.0700e+01,  ..., -3.7994e-01,\n",
      "          9.9027e+00, -1.3403e+01],\n",
      "        [ 4.7910e-03, -3.1222e+01, -1.3778e+01,  ..., -6.6729e-01,\n",
      "          1.0434e+01, -1.3934e+01],\n",
      "        ...,\n",
      "        [ 9.1031e-01, -2.4391e+01, -2.0609e+01,  ...,  1.5260e-01,\n",
      "          1.0230e+01, -1.3730e+01],\n",
      "        [ 3.8314e-02, -3.2923e+01, -1.2077e+01,  ...,  1.2212e+00,\n",
      "          1.1320e+01, -1.4820e+01],\n",
      "        [ 5.7752e-01,  1.4567e+01, -5.9567e+01,  ..., -8.6984e-01,\n",
      "          9.6744e+00, -1.3174e+01]], device='cuda:0',\n",
      "       grad_fn=<ToCopyBackward0>)\n",
      "tensor([[  0.5253, -20.6802, -24.3198,  ...,   0.1560,   9.9908, -13.4908],\n",
      "        [  0.5377, -35.2861,  -9.7139,  ...,  -1.0291,   9.9875, -13.4875],\n",
      "        [  0.7035,   9.2769, -54.2769,  ...,   1.0722,  11.1978, -14.6978],\n",
      "        ...,\n",
      "        [  0.8915, -10.7279, -34.2721,  ...,   0.8441,  10.7003, -14.2003],\n",
      "        [  0.5919, -43.6604,  -1.3396,  ...,   0.5085,  11.1739, -14.6739],\n",
      "        [  0.5432, -40.5488,  -4.4512,  ...,   0.1029,  10.6222, -14.1222]],\n",
      "       device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for Xtrain in train_loader:\n",
    "    Xtrain = Xtrain[0].to(DEVICE)\n",
    "    print(g_x(Xtrain))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y, args):\n",
    "    obj_cost = cost_fn(Y)\n",
    "    ineq_cost = torch.linalg.vector_norm(torch.clamp(g_x(Y)), min=0)\n",
    "\n",
    "    return obj_cost + args['softWeight'] * ineq_cost\n",
    "\n",
    "\n",
    "def grad_step(X, args):\n",
    "    gamma = args['ineqGradLr'] \n",
    "    steps = args['ineqGradSteps'] \n",
    "    momentum = args['ineqGradMomentum'] \n",
    "    old_x_step = 0\n",
    "    X_new = X\n",
    "    for i in range(steps):\n",
    "        x_step = del_ineq(X_new)\n",
    "        step = gamma * x_step + momentum * old_x_step\n",
    "        X_new = X_new - step\n",
    "        old_x_step = step\n",
    "    \n",
    "    return X_new\n",
    "\n",
    "\n",
    "def eval_dataset(net, loader, args):\n",
    "    avg_loss = 0\n",
    "    n = 0\n",
    "    for X in loader:\n",
    "        n += 1\n",
    "        X = X[0]\n",
    "        loss, Y_new = eval(net, X, args)\n",
    "        avg_loss += loss\n",
    "        # print('Test set {0} loss = {1} Y_new = {2}'.format(i, loss, Y_new))\n",
    "    return avg_loss / n\n",
    "\n",
    "def eval(net, X, args):\n",
    "    # print(X)\n",
    "    Y = net(X)\n",
    "    Y_new = grad_step(Y, args)\n",
    "    return loss(Y_new, args), Y_new\n",
    "\n",
    "def train(net, train_loader, test_loader, args):\n",
    "    solver_opt = optim.Adam(net.parameters(), lr=args['trainLr'])\n",
    "    for epoch in range(args['epochs']):\n",
    "        net.train()\n",
    "        for i, Xtrain in enumerate(train_loader):\n",
    "            solver_opt.zero_grad()\n",
    "            Xtrain = Xtrain[0].to(DEVICE)\n",
    "            Yhat_train = net(Xtrain)\n",
    "            Ynew_train = grad_step(Yhat_train, args)\n",
    "            train_loss = loss(Ynew_train, args)\n",
    "            train_loss.sum().backward()\n",
    "            solver_opt.step()\n",
    "        net.eval()\n",
    "        test_loss = eval_dataset(net, test_loader, args)\n",
    "        print('Epoch = {0} loss = {1}'.format(epoch, test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'del_ineq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     11\u001b[0m broken_test \u001b[39m=\u001b[39m [\u001b[39m3.5\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m10.4\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m6.6\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4.1\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m4.9\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m6.4\u001b[39m\u001b[39m+\u001b[39m\u001b[39m7\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.9\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4.9\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.9\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[39m# X = grad_step(broken_test, 1e-4, 0.5, 10)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# print(X)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# print(cost_fn(X))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[39m# eval_dataset(net, test_loader, args)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m train(net, train_loader, test_loader, args)\n\u001b[1;32m     21\u001b[0m net\u001b[39m.\u001b[39meval()\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m test \u001b[39min\u001b[39;00m test_loader:\n",
      "Cell \u001b[0;32mIn[10], line 48\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, test_loader, args)\u001b[0m\n\u001b[1;32m     46\u001b[0m Xtrain \u001b[39m=\u001b[39m Xtrain[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m     47\u001b[0m Yhat_train \u001b[39m=\u001b[39m net(Xtrain)\n\u001b[0;32m---> 48\u001b[0m Ynew_train \u001b[39m=\u001b[39m grad_step(Yhat_train, args)\n\u001b[1;32m     49\u001b[0m train_loss \u001b[39m=\u001b[39m loss(Ynew_train, args)\n\u001b[1;32m     50\u001b[0m train_loss\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m, in \u001b[0;36mgrad_step\u001b[0;34m(X, args)\u001b[0m\n\u001b[1;32m     13\u001b[0m X_new \u001b[39m=\u001b[39m X\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[0;32m---> 15\u001b[0m     x_step \u001b[39m=\u001b[39m del_ineq(X_new)\n\u001b[1;32m     16\u001b[0m     step \u001b[39m=\u001b[39m gamma \u001b[39m*\u001b[39m x_step \u001b[39m+\u001b[39m momentum \u001b[39m*\u001b[39m old_x_step\n\u001b[1;32m     17\u001b[0m     X_new \u001b[39m=\u001b[39m X_new \u001b[39m-\u001b[39m step\n",
      "\u001b[0;31mNameError\u001b[0m: name 'del_ineq' is not defined"
     ]
    }
   ],
   "source": [
    "net = OptimizerNet(n_unknowns, 200, n_unknowns).to(DEVICE)\n",
    "args = {}\n",
    "\n",
    "args['softWeight'] = 10\n",
    "args['trainLr'] = 0.001\n",
    "args['ineqGradLr'] = 0.001\n",
    "args['ineqGradSteps'] = 10\n",
    "args['ineqGradMomentum'] = .5\n",
    "args['epochs'] = 1000\n",
    "\n",
    "broken_test = [3.5, 7, 10.4, -6.6+7, -4.1+7, 0, 4.9+7, 6.4+7, -1.9, -4, -4.9, -4, -1.9]\n",
    "# X = grad_step(broken_test, 1e-4, 0.5, 10)\n",
    "# print(X)\n",
    "# print(cost_fn(X))\n",
    "# print(torch.linalg.vector_norm(torch.clamp(g_x(np.array(broken_test).flatten()), min=0)))\n",
    "# print(torch.linalg.vector_norm(torch.clamp(g_x(X.flatten()), min=0)))\n",
    "\n",
    "# eval_dataset(net, test_loader, args)\n",
    "train(net, train_loader, test_loader, args)\n",
    "\n",
    "net.eval()\n",
    "for test in test_loader:\n",
    "    print(net(test[0]))\n",
    "    print(cost_fn(net(test[0]).cpu().detach().numpy().flatten()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
